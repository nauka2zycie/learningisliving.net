This file was created by bibmanager
https://pcubillos.github.io/bibmanager/

@online{adlerDeepBayesianInversion2018a,
  title = {Deep {{Bayesian Inversion}}},
  author = {Adler, Jonas and Öktem, Ozan},
  date = {2018-11-14},
  eprint = {1811.05910},
  eprinttype = {arxiv},
  primaryclass = {cs, math, stat},
  url = {http://arxiv.org/abs/1811.05910},
  urldate = {2021-01-06},
  abstract = {Characterizing statistical properties of solutions of inverse problems is essential for decision making. Bayesian inversion offers a tractable framework for this purpose, but current approaches are computationally unfeasible for most realistic imaging applications in the clinic. We introduce two novel deep learning based methods for solving large-scale inverse problems using Bayesian inversion: a sampling based method using a WGAN with a novel mini-discriminator and a direct approach that trains a neural network using a novel loss function. The performance of both methods is demonstrated on image reconstruction in ultra low dose 3D helical CT. We compute the posterior mean and standard deviation of the 3D images followed by a hypothesis test to assess whether a "dark spot" in the liver of a cancer stricken patient is present. Both methods are computationally efficient and our evaluation shows very promising performance that clearly supports the claim that Bayesian inversion is usable for 3D imaging in time critical applications.},
  archiveprefix = {arXiv},
  keywords = {Bayesian&info&zero-shot,Computer Science - Machine Learning,GAN&games&dynamics,Mathematics - Statistics Theory,Statistics - Machine Learning},
  file = {/home/nauka/Zotero/storage/6H4V9RA3/Adler and Öktem - 2018 - Deep Bayesian Inversion.pdf;/home/nauka/Zotero/storage/ZYGEQHPF/1811.html}
}

@article{ajayiApproximateSubmodularityIts,
  title = {Approximate {{Submodularity}} and {{Its Implications}} in {{Discrete Optimization}}},
  author = {Ajayi, Temitayo and Lee, Taewoo and Schaefer, Andrew J},
  pages = {49},
  abstract = {Submodularity, a discrete analog of convexity, is a key property in discrete optimization that features in the construction of valid inequalities and analysis of the greedy algorithm. In this paper, we broaden the approximate submodularity literature, which so far has largely focused on variants of greedy algorithms and iterative approaches. We define metrics that quantify approximate submodularity and use these metrics to derive properties about approximate submodularity preservation and extensions of set functions. We show that previous analyses of mixed-integer sets, such as the submodular knapsack polytope, can be extended to the approximate submodularity setting. In addition, we demonstrate that greedy algorithm bounds based on our notions of approximate submodularity are competitive with those in the literature, which we illustrate using a generalization of the uncapacitated facility location problem.},
  langid = {english},
  file = {/home/nauka/Zotero/storage/PQ5U4ITA/Ajayi et al. - Approximate Submodularity and Its Implications in .pdf}
}

@online{bakkerExperimentalDesignMRI2020,
  title = {Experimental Design for {{MRI}} by Greedy Policy Search},
  author = {Bakker, Tim and van Hoof, Herke and Welling, Max},
  options = {useprefix=true},
  date = {2020-10-30},
  eprint = {2010.16262},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/2010.16262},
  urldate = {2020-11-09},
  abstract = {In today's clinical practice, magnetic resonance imaging (MRI) is routinely accelerated through subsampling of the associated Fourier domain. Currently, the construction of these subsampling strategies - known as experimental design - relies primarily on heuristics. We propose to learn experimental design strategies for accelerated MRI with policy gradient methods. Unexpectedly, our experiments show that a simple greedy approximation of the objective leads to solutions nearly on-par with the more general non-greedy approach. We offer a partial explanation for this phenomenon rooted in greater variance in the non-greedy objective's gradient estimates, and experimentally verify that this variance hampers non-greedy models in adapting their policies to individual MR images. We empirically show that this adaptivity is key to improving subsampling designs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,RL},
  annotation = {0 citations (Semantic Scholar/arXiv) [2020-12-13]},
  file = {/home/nauka/Zotero/storage/5JMXSBI2/Bakker et al_2020_Experimental design for MRI by greedy policy search.pdf;/home/nauka/Zotero/storage/QHPTEIXG/2010.html}
}

@article{baldassarreLearningBasedCompressiveSubsampling2016,
  title = {Learning-{{Based Compressive Subsampling}}},
  author = {Baldassarre, Luca and Li, Yen-Huan and Scarlett, Jonathan and Gözcü, Baran and Bogunovic, Ilija and Cevher, Volkan},
  date = {2016-06},
  journaltitle = {IEEE Journal of Selected Topics in Signal Processing},
  volume = {10},
  number = {4},
  pages = {809--822},
  issn = {1941-0484},
  doi = {10.1109/JSTSP.2016.2548442},
  abstract = {The problem of recovering a structured signal x ∈ Cp from a set of dimensionality-reduced linear measurements b = Ax arises in a variety of applications, such as medical imaging, spectroscopy, Fourier optics, and computerized tomography. Due to computational and storage complexity or physical constraints imposed by the problem, the measurement matrix A ∈ Cn×p is often of the form A = PΩΨ for some orthonormal basis matrix Ψ ∈ CP×P and subsampling operator PΩ : Cp → Cn that selects the rows indexed by Ω. This raises the fundamental question of how best to choose the index set Ω in order to optimize the recovery performance. Previous approaches to addressing this question rely on nonuniform random subsampling using application-specific knowledge of the structure of x. In this paper, we instead take a principled learning-based approach in which affixed index set is chosen based on a set of training signals x1, . . . , xm. We formulate combinatorial optimization problems seeking to maximize the energy captured in these signals in an average-case or worst-case sense, and we show that these can be efficiently solved either exactly or approximately via the identification of modularity and submodularity structures. We provide both deterministic and statistical theoretical guarantees showing how the resulting measurement matrices perform on signals differing from the training signals, and we provide numerical examples showing our approach to be effective on a variety of data sets.},
  eventtitle = {{{IEEE Journal}} of {{Selected Topics}} in {{Signal Processing}}},
  keywords = {Compressive sensing,data-driven sensing design,Decoding,Indexes,learning-based measurement design,Noise measurement,non-uniform subsampling,nonuniform subsampling,Optimization,scientific and medical imaging,Sparse matrices,structured sparsity,submodular optimization,Training,Training data},
  file = {/home/nauka/Zotero/storage/DKSSZ79Z/Baldassarre et al. - 2016 - Learning-Based Compressive Subsampling.pdf}
}

@inproceedings{belloNeuralOptimizerSearch2017a,
  title = {Neural {{Optimizer Search}} with {{Reinforcement Learning}}},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Bello, Irwan and Zoph, Barret and Vasudevan, Vijay and Le, Quoc V.},
  date = {2017-07-17},
  pages = {459--468},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {http://proceedings.mlr.press/v70/bello17a.html},
  urldate = {2021-05-20},
  abstract = {We present an approach to automate the process of discovering optimization methods, with a focus on deep learning architectures. We train a Recurrent Neural Network controller to generate a string ...},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/home/nauka/Zotero/storage/FR2JN8J9/Bello et al. - 2017 - Neural Optimizer Search with Reinforcement Learnin.pdf;/home/nauka/Zotero/storage/M6GXPTYW/bello17a.html}
}

@article{griswoldGeneralizedAutocalibratingPartially2002,
  title = {Generalized Autocalibrating Partially Parallel Acquisitions ({{GRAPPA}})},
  author = {Griswold, Mark A. and Jakob, Peter M. and Heidemann, Robin M. and Nittka, Mathias and Jellus, Vladimir and Wang, Jianmin and Kiefer, Berthold and Haase, Axel},
  date = {2002-06},
  journaltitle = {Magnetic Resonance in Medicine},
  shortjournal = {Magn. Reson. Med.},
  volume = {47},
  number = {6},
  pages = {1202--1210},
  issn = {0740-3194, 1522-2594},
  doi = {10.1002/mrm.10171},
  url = {http://doi.wiley.com/10.1002/mrm.10171},
  urldate = {2021-05-27},
  langid = {english},
  file = {/home/nauka/Zotero/storage/8338QTL7/Griswold et al. - 2002 - Generalized autocalibrating partially parallel acq.pdf}
}

@article{guGANOptimalTransport,
  title = {{{GAN}}, {{Optimal Transport}} and {{Monge}}-{{Ampère Equation}}},
  author = {Gu, David Xianfeng and Yau, Shing-Tung},
  pages = {89},
  langid = {english},
  file = {/home/nauka/Zotero/storage/EUPY9LZT/Gu and Yau - GAN, Optimal Transport and Monge-Ampère Equation.pdf}
}

@article{gozcuLearningBasedCompressiveMRI2018,
  title = {Learning-{{Based Compressive MRI}}},
  author = {Gözcü, Baran and Mahabadi, Rabeeh Karimi and Li, Yen-Huan and Ilıcak, Efe and Çukur, Tolga and Scarlett, Jonathan and Cevher, Volkan},
  date = {2018-06},
  journaltitle = {IEEE Transactions on Medical Imaging},
  volume = {37},
  number = {6},
  pages = {1394--1406},
  issn = {1558-254X},
  doi = {10.1109/TMI.2018.2832540},
  abstract = {In the area of magnetic resonance imaging (MRI), an extensive range of non-linear reconstruction algorithms has been proposed which can be used with general Fourier subsampling patterns. However, the design of these subsampling patterns has typically been considered in isolation from the reconstruction rule and the anatomy under consideration. In this paper, we propose a learning-based framework for optimizing MRI subsampling patterns for a specific reconstruction rule and anatomy, considering both the noiseless and noisy settings. Our learning algorithm has access to a representative set of training signals, and searches for a sampling pattern that performs well on average for the signals in this set. We present a novel parameter-free greedy mask selection method and show it to be effective for a variety of reconstruction rules and performance metrics. Moreover, we also support our numerical findings by providing a rigorous justification of our framework via statistical learning theory.},
  eventtitle = {{{IEEE Transactions}} on {{Medical Imaging}}},
  keywords = {Compressed sensing,compressive sensing,Decoding,greedy algorithms,Image reconstruction,learning-based subsampling,Machine learning,Magnetic resonance imaging,Reconstruction algorithms,Training},
  file = {/home/nauka/Zotero/storage/G68D2CAM/Gözcü et al. - 2018 - Learning-Based Compressive MRI.pdf}
}

@inproceedings{heBagTricksImage2019,
  title = {Bag of {{Tricks}} for {{Image Classification}} with {{Convolutional Neural Networks}}},
  author = {He, Tong and Zhang, Zhi and Zhang, Hang and Zhang, Zhongyue and Xie, Junyuan and Li, Mu},
  date = {2019},
  pages = {558--567},
  url = {https://openaccess.thecvf.com/content_CVPR_2019/html/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.html},
  urldate = {2021-05-20},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  file = {/home/nauka/Zotero/storage/ZCKSX7XH/He et al. - 2019 - Bag of Tricks for Image Classification with Convol.pdf;/home/nauka/Zotero/storage/FGVLCT44/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.html}
}

@online{jalalInstanceOptimalCompressedSensing2021,
  title = {Instance-{{Optimal Compressed Sensing}} via {{Posterior Sampling}}},
  author = {Jalal, Ajil and Karmalkar, Sushrut and Dimakis, Alexandros G. and Price, Eric},
  date = {2021-06-21},
  eprint = {2106.11438},
  eprinttype = {arxiv},
  primaryclass = {cs, math, stat},
  url = {http://arxiv.org/abs/2106.11438},
  urldate = {2021-07-08},
  abstract = {We characterize the measurement complexity of compressed sensing of signals drawn from a known prior distribution, even when the support of the prior is the entire space (rather than, say, sparse vectors). We show for Gaussian measurements and \textbackslash emph\{any\} prior distribution on the signal, that the posterior sampling estimator achieves near-optimal recovery guarantees. Moreover, this result is robust to model mismatch, as long as the distribution estimate (e.g., from an invertible generative model) is close to the true distribution in Wasserstein distance. We implement the posterior sampling estimator for deep generative priors using Langevin dynamics, and empirically find that it produces accurate estimates with more diversity than MAP.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/nauka/Zotero/storage/NVIHC6FX/Jalal et al. - 2021 - Instance-Optimal Compressed Sensing via Posterior .pdf;/home/nauka/Zotero/storage/22XR92T2/2106.html}
}

@article{krauseSubmodularityMLTheory,
  title = {Submodularity and {{ML}}: Theory and {{Applications}} – {{Part II}}},
  author = {Krause, Andreas},
  pages = {75},
  langid = {english},
  file = {/home/nauka/Zotero/storage/JBTHD3RY/Krause - Submodularity and ML Theory and Applications – Pa.pdf}
}

@inproceedings{lavesWellCalibratedRegressionUncertainty2020,
  title = {Well-{{Calibrated Regression Uncertainty}} in {{Medical Imaging}} with {{Deep Learning}}},
  author = {Laves, Max-Heinrich and Ihler, Sontje and Fast, Jacob F. and Kahrs, Lüder A. and Ortmaier, Tobias},
  date = {2020-01-25},
  url = {https://openreview.net/forum?id=CecZ_0t79q},
  urldate = {2021-05-19},
  abstract = {We recalibrate underestimated predictive uncertainty for different regression tasks in medical imaging.},
  eventtitle = {Medical {{Imaging}} with {{Deep Learning}}},
  langid = {english},
  file = {/home/nauka/Zotero/storage/WLGVSUDR/Laves et al. - 2020 - Well-Calibrated Regression Uncertainty in Medical .pdf;/home/nauka/Zotero/storage/SCDYFYAZ/forum.html}
}

@article{linPacGANPowerTwo2020,
  title = {{{PacGAN}}: The {{Power}} of {{Two Samples}} in {{Generative Adversarial Networks}}},
  shorttitle = {{{PacGAN}}},
  author = {Lin, Zinan and Khetan, Ashish and Fanti, Giulia and Oh, Sewoong},
  date = {2020-05},
  journaltitle = {IEEE Journal on Selected Areas in Information Theory},
  volume = {1},
  number = {1},
  pages = {324--335},
  issn = {2641-8770},
  doi = {10.1109/JSAIT.2020.2983071},
  abstract = {Generative adversarial networks (GANs) are innovative techniques for learning generative models of complex data distributions from samples. Despite remarkable improvements in generating realistic images, one of their major shortcomings is the fact that in practice, they tend to produce samples with little diversity, even when trained on diverse datasets. This phenomenon, known as mode collapse, has been the main focus of several recent advances in GANs. Yet there is little understanding of why mode collapse happens and why recently-proposed approaches mitigate mode collapse. We propose a principled approach to handle mode collapse called packing. The main idea is to modify the discriminator to make decisions based on multiple samples from the same class, either real or artificially generated. We borrow analysis tools from binary hypothesis testing-in particular the seminal result of (Blackwell, 1953)-to prove a fundamental connection between packing and mode collapse. We show that packing naturally penalizes generators with mode collapse, thereby favoring generator distributions with less mode collapse during the training process. Numerical experiments on benchmark datasets suggests that packing provides significant improvements in practice as well.},
  eventtitle = {{{IEEE Journal}} on {{Selected Areas}} in {{Information Theory}}},
  keywords = {Data models,data processing inequalities,Gallium nitride,Generative adversarial networks,Generators,hypothesis testing,Information theory,mode collapse,Neural networks,Testing,Training},
  file = {/home/nauka/Zotero/storage/IGRNAL5Y/Lin et al. - 2020 - PacGAN The Power of Two Samples in Generative Adv.pdf;/home/nauka/Zotero/storage/46NDRATT/9046238.html}
}

@article{liuRethinkingSkipConnection,
  title = {Rethinking {{Skip Connection}} with {{Layer Normalization}}},
  author = {Liu, Fenglin and Ren, Xuancheng and Zhang, Zhiyuan and Sun, Xu and Zou, Yuexian},
  pages = {13},
  abstract = {Skip connection is a widely-used technique to improve the performance and the convergence of deep neural networks, which is believed to relieve the difficulty in optimization due to non-linearity by propagating a linear component through the neural network layers. However, from another point of view, it can also be seen as a modulating mechanism between the input and the output, with the input scaled by a pre-defined value one. In this work, we investigate how the scale factors in the effectiveness of the skip connection and reveal that a trivial adjustment of the scale will lead to spurious gradient exploding or vanishing in line with the deepness of the models, which could by addressed by normalization, in particular, layer normalization, which induces consistent improvements over the plain skip connection. Inspired by the findings, we further propose to adaptively adjust the scale of the input by recursively applying skip connection with layer normalization, which promotes the performance substantially and generalizes well across diverse tasks including both machine translation and image classification datasets.},
  langid = {english},
  file = {/home/nauka/Zotero/storage/N4WDWI2I/Liu et al. - Rethinking Skip Connection with Layer Normalizatio.pdf}
}

@article{luOptimalTransportWGAN,
  title = {Optimal {{Transport And WGAN}}},
  author = {Lu, Yiping},
  pages = {41},
  langid = {english},
  file = {/home/nauka/Zotero/storage/GZHXLB3C/Lu - Optimal Transport And WGAN.pdf}
}

@online{ohUnpairedDeepLearning2020a,
  title = {Unpaired {{Deep Learning}} for {{Accelerated MRI}} Using {{Optimal Transport Driven CycleGAN}}},
  author = {Oh, Gyutaek and Sim, Byeongsu and Chung, Hyungjin and Sunwoo, Leonard and Ye, Jong Chul},
  date = {2020-08-29},
  eprint = {2008.12967},
  eprinttype = {arxiv},
  primaryclass = {cs, eess, stat},
  url = {http://arxiv.org/abs/2008.12967},
  urldate = {2021-08-09},
  abstract = {Recently, deep learning approaches for accelerated MRI have been extensively studied thanks to their high performance reconstruction in spite of significantly reduced runtime complexity. These neural networks are usually trained in a supervised manner, so matched pairs of subsampled and fully sampled k-space data are required. Unfortunately, it is often difficult to acquire matched fully sampled k-space data, since the acquisition of fully sampled k-space data requires long scan time and often leads to the change of the acquisition protocol. Therefore, unpaired deep learning without matched label data has become a very important research topic. In this paper, we propose an unpaired deep learning approach using a optimal transport driven cycle-consistent generative adversarial network (OT-cycleGAN) that employs a single pair of generator and discriminator. The proposed OT-cycleGAN architecture is rigorously derived from a dual formulation of the optimal transport formulation using a specially designed penalized least squares cost. The experimental results show that our method can reconstruct high resolution MR images from accelerated k- space data from both single and multiple coil acquisition, without requiring matched reference data.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing,Statistics - Machine Learning}
}

@online{pezzottiAdaptiveIntelligenceAlgorithm2020,
  title = {An {{Adaptive Intelligence Algorithm}} for {{Undersampled Knee MRI Reconstruction}}},
  author = {Pezzotti, Nicola and Yousefi, Sahar and Elmahdy, Mohamed S. and van Gemert, Jeroen and Schülke, Christophe and Doneva, Mariya and Nielsen, Tim and Kastryulin, Sergey and Lelieveldt, Boudewijn P. F. and van Osch, Matthias J. P. and de Weerdt, Elwin and Staring, Marius},
  options = {useprefix=true},
  date = {2020-10-27},
  eprint = {2004.07339},
  eprinttype = {arxiv},
  primaryclass = {cs, eess},
  url = {http://arxiv.org/abs/2004.07339},
  urldate = {2021-06-14},
  abstract = {Adaptive intelligence aims at empowering machine learning techniques with the additional use of domain knowledge. In this work, we present the application of adaptive intelligence to accelerate MR acquisition. Starting from undersampled k-space data, an iterative learning-based reconstruction scheme inspired by compressed sensing theory is used to reconstruct the images. We adopt deep neural networks to refine and correct prior reconstruction assumptions given the training data. The network was trained and tested on a knee MRI dataset from the 2019 fastMRI challenge organized by Facebook AI Research and NYU Langone Health. All submissions to the challenge were initially ranked based on similarity with a known groundtruth, after which the top 4 submissions were evaluated radiologically. Our method was evaluated by the fastMRI organizers on an independent challenge dataset. It ranked \#1, shared \#1, and \#3 on respectively the 8x accelerated multi-coil, the 4x multi-coil, and the 4x single-coil track. This demonstrates the superior performance and wide applicability of the method.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/nauka/Zotero/storage/3H5WFC72/Pezzotti et al. - 2020 - An Adaptive Intelligence Algorithm for Undersample.pdf;/home/nauka/Zotero/storage/YKQ4TGEW/2004.html}
}

@inproceedings{pinedaActiveMRKspace2020,
  ids = {pinedaActiveMRKspace2020c},
  title = {Active {{MR}} K-Space {{Sampling}} with {{Reinforcement Learning}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} – {{MICCAI}} 2020},
  author = {Pineda, Luis and Basu, Sumana and Romero, Adriana and Calandra, Roberto and Drozdzal, Michal},
  editor = {Martel, Anne L. and Abolmaesumi, Purang and Stoyanov, Danail and Mateus, Diana and Zuluaga, Maria A. and Zhou, S. Kevin and Racoceanu, Daniel and Joskowicz, Leo},
  date = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {23--33},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-59713-9_3},
  url = {10.1007/978-3-030-59713-9_3},
  abstract = {Deep learning approaches have recently shown great promise in accelerating magnetic resonance image (MRI) acquisition. The majority of existing work have focused on designing better reconstruction models given a pre-determined acquisition trajectory, ignoring the question of trajectory optimization. In this paper, we focus on learning acquisition trajectories given a fixed image reconstruction model. We formulate the problem as a sequential decision process and propose the use of reinforcement learning to solve it. Experiments on a large scale public MRI dataset of knees show that our proposed models significantly outperform the state-of-the-art in active MRI acquisition, over a large range of acceleration factors.},
  isbn = {978-3-030-59713-9},
  langid = {english},
  keywords = {Active MRI acquisition,Reinforcement learning},
  annotation = {1 citations (Semantic Scholar/DOI) [2020-12-13]},
  file = {/home/nauka/Zotero/storage/JERUUNY3/Pineda et al. - 2020 - Active MR k-space Sampling with Reinforcement Lear.pdf;/home/nauka/Zotero/storage/LEULLWET/Pineda et al_2020_Active MR k-space Sampling with Reinforcement Learning.pdf}
}

@online{pinedaActiveMRKspace2020b,
  ids = {pinedaActiveMRKspace2020a},
  title = {Active {{MR}} K-Space {{Sampling}} with {{Reinforcement Learning}}},
  author = {Pineda, Luis and Basu, Sumana and Romero, Adriana and Calandra, Roberto and Drozdzal, Michal},
  date = {2020-07-20},
  eprint = {2007.10469},
  eprinttype = {arxiv},
  primaryclass = {cs, eess},
  url = {http://arxiv.org/abs/2007.10469},
  urldate = {2020-08-11},
  abstract = {Deep learning approaches have recently shown great promise in accelerating magnetic resonance image (MRI) acquisition. The majority of existing work have focused on designing better reconstruction models given a pre-determined acquisition trajectory, ignoring the question of trajectory optimization. In this paper, we focus on learning acquisition trajectories given a fixed image reconstruction model. We formulate the problem as a sequential decision process and propose the use of reinforcement learning to solve it. Experiments on a large scale public MRI dataset of knees show that our proposed models significantly outperform the state-of-the-art in active MRI acquisition, over a large range of acceleration factors.},
  archiveprefix = {arXiv},
  version = {1},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  annotation = {1 citations (Semantic Scholar/arXiv) [2020-12-13]},
  file = {/home/nauka/Zotero/storage/4L88B7NQ/Pineda et al_2020_Active MR k-space Sampling with Reinforcement Learning.pdf;/home/nauka/Zotero/storage/5DCGKDLZ/Pineda et al_2020_Active MR k-space Sampling with Reinforcement Learning.pdf;/home/nauka/Zotero/storage/IYR9R5LS/2007.html;/home/nauka/Zotero/storage/M7TC2ZAG/2007.html}
}

@article{putzkyInvertLearnInvertb,
  title = {Invert to {{Learn}} to {{Invert}}},
  author = {Putzky, Patrick and Welling, Max},
  pages = {11},
  abstract = {Iterative learning to infer approaches have become popular solvers for inverse problems. However, their memory requirements during training grow linearly with model depth, limiting in practice model expressiveness. In this work, we propose an iterative inverse model with constant memory that relies on invertible networks to avoid storing intermediate activations. As a result, the proposed approach allows us to train models with 400 layers on 3D volumes in an MRI image reconstruction task. In experiments on a public data set, we demonstrate that these deeper, and thus more expressive, networks perform state-of-the-art image reconstruction.},
  langid = {english},
  file = {/home/nauka/Zotero/storage/KSRI268M/Putzky and Welling - Invert to Learn to Invert.pdf}
}

@online{putzkyIRIMAppliedFastMRI2019,
  title = {I-{{RIM}} Applied to the {{fastMRI}} Challenge},
  author = {Putzky, Patrick and Karkalousos, Dimitrios and Teuwen, Jonas and Miriakov, Nikita and Bakker, Bart and Caan, Matthan and Welling, Max},
  date = {2019-10-20},
  eprint = {1910.08952},
  eprinttype = {arxiv},
  primaryclass = {cs, eess},
  url = {http://arxiv.org/abs/1910.08952},
  urldate = {2021-05-11},
  abstract = {We, team AImsterdam, summarize our submission to the fastMRI challenge (Zbontar et al., 2018). Our approach builds on recent advances in invertible learning to infer models as presented in Putzky and Welling (2019). Both, our single-coil and our multi-coil model share the same basic architecture.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/nauka/Zotero/storage/ZF5K3XKI/Putzky et al. - 2019 - i-RIM applied to the fastMRI challenge.pdf;/home/nauka/Zotero/storage/MAVKC3EF/1910.html}
}

@online{sanchezScalableLearningBasedSampling2020,
  title = {Scalable {{Learning}}-{{Based Sampling Optimization}} for {{Compressive Dynamic MRI}}},
  author = {Sanchez, Thomas and Gözcü, Baran and van Heeswijk, Ruud B. and Eftekhari, Armin and Ilıcak, Efe and Çukur, Tolga and Cevher, Volkan},
  options = {useprefix=true},
  date = {2020-03-16},
  eprint = {1902.00386},
  eprinttype = {arxiv},
  primaryclass = {cs, eess},
  url = {http://arxiv.org/abs/1902.00386},
  urldate = {2021-06-02},
  abstract = {Compressed sensing applied to magnetic resonance imaging (MRI) allows to reduce the scanning time by enabling images to be reconstructed from highly undersampled data. In this paper, we tackle the problem of designing a sampling mask for an arbitrary reconstruction method and a limited acquisition budget. Namely, we look for an optimal probability distribution from which a mask with a fixed cardinality is drawn. We demonstrate that this problem admits a compactly supported solution, which leads to a deterministic optimal sampling mask. We then propose a stochastic greedy algorithm that (i) provides an approximate solution to this problem, and (ii) resolves the scaling issues of [1,2]. We validate its performance on in vivo dynamic MRI with retrospective undersampling, showing that our method preserves the performance of [1,2] while reducing the computational burden by a factor close to 200.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/nauka/Zotero/storage/EQJ4TKU4/Sanchez et al. - 2020 - Scalable Learning-Based Sampling Optimization for .pdf;/home/nauka/Zotero/storage/WRQLC9LS/1902.html}
}

@online{simkinNumberQueensConfigurations2021,
  title = {The Number of \$n\$-Queens Configurations},
  author = {Simkin, Michael},
  date = {2021-08-18},
  eprint = {2107.13460},
  eprinttype = {arxiv},
  primaryclass = {math},
  url = {http://arxiv.org/abs/2107.13460},
  urldate = {2021-09-21},
  abstract = {The \$n\$-queens problem is to determine \$\textbackslash mathcal\{Q\}(n)\$, the number of ways to place \$n\$ mutually non-threatening queens on an \$n \textbackslash times n\$ board. We show that there exists a constant \$\textbackslash alpha = 1.942 \textbackslash pm 3 \textbackslash times 10\^\{-3\}\$ such that \$\textbackslash mathcal\{Q\}(n) = ((1 \textbackslash pm o(1))ne\^\{-\textbackslash alpha\})\^n\$. The constant \$\textbackslash alpha\$ is characterized as the solution to a convex optimization problem in \$\textbackslash mathcal\{P\}([-1/2,1/2]\^2)\$, the space of Borel probability measures on the square. The chief innovation is the introduction of limit objects for \$n\$-queens configurations, which we call "queenons". These are a convex set in \$\textbackslash mathcal\{P\}([-1/2,1/2]\^2)\$. We define an entropy function that counts the number of \$n\$-queens configurations that approximate a given queenon. The upper bound uses the entropy method. For the lower bound we describe a randomized algorithm that constructs a configuration near a prespecified queenon and whose entropy matches that found in the upper bound. The enumeration of \$n\$-queens configurations is then obtained by maximizing the (concave) entropy function in the space of queenons. Along the way we prove a large deviations principle for \$n\$-queens configurations that can be used to study their typical structure.},
  archiveprefix = {arXiv},
  keywords = {05A16; 05A05; 05B30,Mathematics - Combinatorics},
  file = {/home/nauka/Zotero/storage/X3HVIFF9/Simkin - 2021 - The number of $n$-queens configurations.pdf;/home/nauka/Zotero/storage/CJZPI9YX/2107.html}
}

@inproceedings{sriramEndtoEndVariationalNetworks2020a,
  title = {End-to-{{End Variational Networks}} for {{Accelerated MRI Reconstruction}}},
  booktitle = {Medical {{Image Computing}} and {{Computer Assisted Intervention}} – {{MICCAI}} 2020},
  author = {Sriram, Anuroop and Zbontar, Jure and Murrell, Tullie and Defazio, Aaron and Zitnick, C. Lawrence and Yakubova, Nafissa and Knoll, Florian and Johnson, Patricia},
  editor = {Martel, Anne L. and Abolmaesumi, Purang and Stoyanov, Danail and Mateus, Diana and Zuluaga, Maria A. and Zhou, S. Kevin and Racoceanu, Daniel and Joskowicz, Leo},
  date = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {64--73},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-59713-9_7},
  abstract = {The slow acquisition speed of magnetic resonance imaging (MRI) has led to the development of two complementary methods: acquiring multiple views of the anatomy simultaneously (parallel imaging) and acquiring fewer samples than necessary for traditional signal processing methods (compressed sensing). While the combination of these methods has the potential to allow much faster scan times, reconstruction from such undersampled multi-coil data has remained an open problem. In this paper, we present a new approach to this problem that extends previously proposed variational methods by learning fully end-to-end. Our method obtains new state-of-the-art results on the fastMRI dataset [16] for both brain and knee MRIs.},
  isbn = {978-3-030-59713-9},
  langid = {english},
  keywords = {Deep learning,End-to-end learning,MRI acceleration},
  file = {/home/nauka/Zotero/storage/3HEPC6PA/Sriram et al. - 2020 - End-to-End Variational Networks for Accelerated MR.pdf}
}

@inproceedings{sriramGrappaNetCombiningParallel2020,
  title = {{{GrappaNet}}: Combining {{Parallel Imaging With Deep Learning}} for {{Multi}}-{{Coil MRI Reconstruction}}},
  shorttitle = {{{GrappaNet}}},
  booktitle = {2020 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Sriram, Anuroop and Zbontar, Jure and Murrell, Tullie and Zitnick, C. Lawrence and Defazio, Aaron and Sodickson, Daniel K.},
  date = {2020-06},
  pages = {14303--14310},
  publisher = {{IEEE}},
  location = {{Seattle, WA, USA}},
  doi = {10.1109/CVPR42600.2020.01432},
  url = {https://ieeexplore.ieee.org/document/9157643/},
  urldate = {2021-05-27},
  abstract = {Magnetic Resonance Image (MRI) acquisition is an inherently slow process which has spurred the development of two different acceleration methods: acquiring multiple correlated samples simultaneously (parallel imaging) and acquiring fewer samples than necessary for traditional signal processing methods (compressed sensing). Both methods provide complementary approaches to accelerating MRI acquisition. In this paper, we present a novel method to integrate traditional parallel imaging methods into deep neural networks that is able to generate high quality reconstructions even for high acceleration factors. The proposed method, called GrappaNet, performs progressive reconstruction by first mapping the reconstruction problem to a simpler one that can be solved by a traditional parallel imaging methods using a neural network, followed by an application of a parallel imaging method, and finally fine-tuning the output with another neural network. The entire network can be trained end-to-end. We present experimental results on the recently released fastMRI dataset [20] and show that GrappaNet can generate higher quality reconstructions than competing methods for both 4× and 8× acceleration.},
  eventtitle = {2020 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-72817-168-5},
  langid = {english},
  file = {/home/nauka/Zotero/storage/KQPKGK3M/Sriram et al. - 2020 - GrappaNet Combining Parallel Imaging With Deep Le.pdf}
}

@online{yinEndtoEndSequentialSampling2021,
  title = {End-to-{{End Sequential Sampling}} and {{Reconstruction}} for {{MR Imaging}}},
  author = {Yin, Tianwei and Wu, Zihui and Sun, He and Dalca, Adrian V. and Yue, Yisong and Bouman, Katherine L.},
  date = {2021-05-13},
  eprint = {2105.06460},
  eprinttype = {arxiv},
  primaryclass = {cs, eess},
  url = {http://arxiv.org/abs/2105.06460},
  urldate = {2021-05-31},
  abstract = {Accelerated MRI shortens acquisition time by subsampling in the measurement k-space. Recovering a high-fidelity anatomical image from subsampled measurements requires close cooperation between two components: (1) a sampler that chooses the subsampling pattern and (2) a reconstructor that recovers images from incomplete measurements. In this paper, we leverage the sequential nature of MRI measurements, and propose a fully differentiable framework that jointly learns a sequential sampling policy simultaneously with a reconstruction strategy. This co-designed framework is able to adapt during acquisition in order to capture the most informative measurements for a particular target (Figure 1). Experimental results on the fastMRI knee dataset demonstrate that the proposed approach successfully utilizes intermediate information during the sampling process to boost reconstruction performance. In particular, our proposed method outperforms the current state-of-the-art learned k-space sampling baseline on up to 96.96\% of test samples. We also investigate the individual and collective benefits of the sequential sampling and co-design strategies. Code and more visualizations are available at http://imaging.cms.caltech.edu/seq-mri},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/nauka/Zotero/storage/YXY779WY/Yin et al. - 2021 - End-to-End Sequential Sampling and Reconstruction .pdf}
}

@article{yuanSARAGANSelfAttentionRelative2020a,
  title = {{{SARA}}-{{GAN}}: Self-{{Attention}} and {{Relative Average Discriminator Based Generative Adversarial Networks}} for {{Fast Compressed Sensing MRI Reconstruction}}},
  shorttitle = {{{SARA}}-{{GAN}}},
  author = {Yuan, Zhenmou and Jiang, Mingfeng and Wang, Yaming and Wei, Bo and Li, Yongming and Wang, Pin and Menpes-Smith, Wade and Niu, Zhangming and Yang, Guang},
  date = {2020-11-26},
  journaltitle = {Frontiers in Neuroinformatics},
  shortjournal = {Front Neuroinform},
  volume = {14},
  eprint = {33324189},
  eprinttype = {pmid},
  pages = {611666},
  issn = {1662-5196},
  doi = {10.3389/fninf.2020.611666},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7726262/},
  urldate = {2021-08-09},
  abstract = {Research on undersampled magnetic resonance image (MRI) reconstruction can increase the speed of MRI imaging and reduce patient suffering. In this paper, an undersampled MRI reconstruction method based on Generative Adversarial Networks with the Self-Attention mechanism and the Relative Average discriminator (SARA-GAN) is proposed. In our SARA-GAN, the relative average discriminator theory is applied to make full use of the prior knowledge, in which half of the input data of the discriminator is true and half is fake. At the same time, a self-attention mechanism is incorporated into the high-layer of the generator to build long-range dependence of the image, which can overcome the problem of limited convolution kernel size. Besides, spectral normalization is employed to stabilize the training process. Compared with three widely used GAN-based MRI reconstruction methods, i.e., DAGAN, DAWGAN, and DAWGAN-GP, the proposed method can obtain a higher peak signal-to-noise ratio (PSNR) and structural similarity index measure(SSIM), and the details of the reconstructed image are more abundant and more realistic for further clinical scrutinization and diagnostic tasks.},
  pmcid = {PMC7726262},
  file = {/home/nauka/Zotero/storage/8P5SUI6U/Yuan et al. - 2020 - SARA-GAN Self-Attention and Relative Average Disc.pdf}
}

@online{zbontarFastMRIOpenDataset2019b,
  title = {{{fastMRI}}: An {{Open Dataset}} and {{Benchmarks}} for {{Accelerated MRI}}},
  shorttitle = {{{fastMRI}}},
  author = {Zbontar, Jure and Knoll, Florian and Sriram, Anuroop and Murrell, Tullie and Huang, Zhengnan and Muckley, Matthew J. and Defazio, Aaron and Stern, Ruben and Johnson, Patricia and Bruno, Mary and Parente, Marc and Geras, Krzysztof J. and Katsnelson, Joe and Chandarana, Hersh and Zhang, Zizhao and Drozdzal, Michal and Romero, Adriana and Rabbat, Michael and Vincent, Pascal and Yakubova, Nafissa and Pinkerton, James and Wang, Duo and Owens, Erich and Zitnick, C. Lawrence and Recht, Michael P. and Sodickson, Daniel K. and Lui, Yvonne W.},
  date = {2019-12-11},
  eprint = {1811.08839},
  eprinttype = {arxiv},
  primaryclass = {physics, stat},
  url = {http://arxiv.org/abs/1811.08839},
  urldate = {2021-05-11},
  abstract = {Accelerating Magnetic Resonance Imaging (MRI) by taking fewer measurements has the potential to reduce medical costs, minimize stress to patients and make MRI possible in applications where it is currently prohibitively slow or expensive. We introduce the fastMRI dataset, a large-scale collection of both raw MR measurements and clinical MR images, that can be used for training and evaluation of machine-learning approaches to MR image reconstruction. By introducing standardized evaluation criteria and a freely-accessible dataset, our goal is to help the community make rapid advances in the state of the art for MR image reconstruction. We also provide a self-contained introduction to MRI for machine learning researchers with no medical imaging background.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Signal Processing,Physics - Medical Physics,Statistics - Machine Learning},
  file = {/home/nauka/Zotero/storage/Q39DUKU4/Zbontar et al. - 2019 - fastMRI An Open Dataset and Benchmarks for Accele.pdf;/home/nauka/Zotero/storage/5KWURHWE/1811.html}
}

@online{zhangReducingUncertaintyUndersampled2019a,
  title = {Reducing {{Uncertainty}} in {{Undersampled MRI Reconstruction}} with {{Active Acquisition}}},
  author = {Zhang, Zizhao and Romero, Adriana and Muckley, Matthew J. and Vincent, Pascal and Yang, Lin and Drozdzal, Michal},
  date = {2019-02-08},
  eprint = {1902.03051},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1902.03051},
  urldate = {2021-05-11},
  abstract = {The goal of MRI reconstruction is to restore a high fidelity image from partially observed measurements. This partial view naturally induces reconstruction uncertainty that can only be reduced by acquiring additional measurements. In this paper, we present a novel method for MRI reconstruction that, at inference time, dynamically selects the measurements to take and iteratively refines the prediction in order to best reduce the reconstruction error and, thus, its uncertainty. We validate our method on a large scale knee MRI dataset, as well as on ImageNet. Results show that (1) our system successfully outperforms active acquisition baselines; (2) our uncertainty estimates correlate with error maps; and (3) our ResNet-based architecture surpasses standard pixel-to-pixel models in the task of MRI reconstruction. The proposed method not only shows high-quality reconstructions but also paves the road towards more applicable solutions for accelerating MRI.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/nauka/Zotero/storage/UA2GASNA/Zhang et al. - 2019 - Reducing Uncertainty in Undersampled MRI Reconstru.pdf;/home/nauka/Zotero/storage/BTTKNZVI/1902.html}
}

@online{zhaoBayesianConditionalGAN2021,
  title = {Bayesian {{Conditional GAN}} for {{MRI Brain Image Synthesis}}},
  author = {Zhao, Gengyan and Meyerand, Mary E. and Birn, Rasmus M.},
  date = {2021-04-22},
  eprint = {2005.11875},
  eprinttype = {arxiv},
  primaryclass = {cs, eess},
  url = {http://arxiv.org/abs/2005.11875},
  urldate = {2021-05-19},
  abstract = {As a powerful technique in medical imaging, image synthesis is widely used in applications such as denoising, super resolution and modality transformation etc. Recently, the revival of deep neural networks made immense progress in the field of medical imaging. Although many deep leaning based models have been proposed to improve the image synthesis accuracy, the evaluation of the model uncertainty, which is highly important for medical applications, has been a missing part. In this work, we propose to use Bayesian conditional generative adversarial network (GAN) with concrete dropout to improve image synthesis accuracy. Meanwhile, an uncertainty calibration approach is involved in the whole pipeline to make the uncertainty generated by Bayesian network interpretable. The method is validated with the T1w to T2w MR image translation with a brain tumor dataset of 102 subjects. Compared with the conventional Bayesian neural network with Monte Carlo dropout, results of the proposed method reach a significant lower RMSE with a p-value of 0.0186. Improvement of the calibration of the generated uncertainty by the uncertainty recalibration method is also illustrated.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing,I.2.10,I.4.5},
  file = {/home/nauka/Zotero/storage/3JRR8IKI/Zhao et al. - 2021 - Bayesian Conditional GAN for MRI Brain Image Synth.pdf;/home/nauka/Zotero/storage/5BKX7AD7/2005.html}
}

@software{ErmongroupNcsnv22021,
  title = {Ermongroup/Ncsnv2},
  date = {2021-06-30T19:57:05Z},
  origdate = {2020-06-17T08:50:11Z},
  url = {https://github.com/ermongroup/ncsnv2},
  urldate = {2021-07-08},
  abstract = {The official PyTorch implementation for NCSNv2 (NeurIPS 2020)},
  organization = {{ermongroup}},
  keywords = {diffusion-models,generative-models,neurips-2020,score-based-generative-modeling,score-matching}
}

